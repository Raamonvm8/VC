{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:49:35.311709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clase de configuracion del media pipe para detectar manos\n",
    "class detectorManos():\n",
    "    def __init__(self, mode=False, maxManos = 2, model_complexity=0, Confdeteccion = 0.5, Confsegui = 0.5):\n",
    "        self.mode = mode\n",
    "        self.maxManos = maxManos\n",
    "        self.model_complexity = model_complexity\n",
    "        self.Confdeteccion = Confdeteccion\n",
    "        self.Confsegui = Confsegui\n",
    "\n",
    "        self.mpmanos = mp.solutions.hands\n",
    "        self.manos = self.mpmanos.Hands(self.mode, self.maxManos, self.model_complexity, self.Confdeteccion, self.Confsegui)\n",
    "        self.dibujo = mp.solutions.drawing_utils\n",
    "        self.tip = [4, 8, 12, 16, 20]\n",
    "\n",
    "    def encontrarManos(self, frame, dibujar = False):\n",
    "        imgcolor = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        self.resultados = self.manos.process(imgcolor)\n",
    "\n",
    "        if self.resultados.multi_hand_landmarks:\n",
    "            for mano in self.resultados.multi_hand_landmarks:\n",
    "                if dibujar:\n",
    "                    self.dibujo.draw_landmarks(frame, mano, self.mpmanos.HAND_CONNECTIONS)\n",
    "        return frame\n",
    "    \n",
    "    def encontrarPosicion(self, frame, ManoNum = 0, dibujar = False):\n",
    "        xlista = []\n",
    "        ylista = []\n",
    "        bbox = []\n",
    "        self.lista = []\n",
    "        if self.resultados.multi_hand_landmarks:\n",
    "            mi_mano = self.resultados.multi_hand_landmarks[ManoNum]\n",
    "            for id, lm in enumerate(mi_mano.landmark):\n",
    "                alto, ancho, c = frame.shape\n",
    "                cx, cy = int(lm.x * ancho), int(lm.y * alto)\n",
    "                xlista.append(cx)\n",
    "                ylista.append(cy)\n",
    "                self.lista.append([id, cx, cy])\n",
    "                if dibujar:\n",
    "                    cv2.circle(frame, (cx, cy), 5, (0, 0, 0), cv2.FILLED)\n",
    "            xmin, xmax = min(xlista), max(xlista)\n",
    "            ymin, ymax = min(ylista), max(ylista)\n",
    "            bbox = xmin, ymin, xmax, ymax\n",
    "            if dibujar:\n",
    "                cv2.rectangle(frame, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20), (0, 255, 0), 2)\n",
    "        return self.lista, bbox\n",
    "    \n",
    "    def dedosArriba(self):\n",
    "        dedos = []\n",
    "        if self.lista[self.tip[0]][1] < self.lista[self.tip[0]-1][1]:\n",
    "            dedos.append(1)\n",
    "        else:\n",
    "            dedos.append(0)\n",
    "        \n",
    "        for id in range(1,5): \n",
    "            if self.lista[self.tip[id]][2] < self.lista[self.tip[id]-2][2]:\n",
    "                dedos.append(1)\n",
    "            else:\n",
    "                dedos.append(0)\n",
    "        return dedos\n",
    "    \n",
    "    def numeroDedos(self):\n",
    "        if(len(self.lista) != 0):\n",
    "            dedos = self.dedosArriba()\n",
    "            return sum(dedos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731599847.028705 2327715 gl_context.cc:357] GL version: 2.1 (2.1 INTEL-18.7.4), renderer: Intel(R) Iris(TM) Plus Graphics 640\n",
      "I0000 00:00:1731599847.062921 2327715 gl_context.cc:357] GL version: 2.1 (2.1 INTEL-18.7.4), renderer: Intel(R) Iris(TM) Plus Graphics 640\n",
      "I0000 00:00:1731599847.112943 2327715 gl_context.cc:357] GL version: 2.1 (2.1 INTEL-18.7.4), renderer: Intel(R) Iris(TM) Plus Graphics 640\n",
      "W0000 00:00:1731599847.147773 2344762 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1731599847.150116 2344775 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1731599847.191314 2344725 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1731599847.192417 2344773 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1731599847.244822 2344724 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "# Ignorar advertencia de protobuf\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf.symbol_database')\n",
    "\n",
    "# Inicializar detector de manos y MediaPipe Face Mesh\n",
    "detector = detectorManos(0.75)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.2)\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.2)\n",
    "\n",
    "# Iniciar la captura de video\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "# Configuración para guardar el video de salida\n",
    "output_video_path = os.path.join(os.getcwd(), 'output.mp4') \n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, vid.get(cv2.CAP_PROP_FPS), \n",
    "                      (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "flag = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = detector.encontrarManos(frame)\n",
    "    manosInfo, cuadro = detector.encontrarPosicion(frame, dibujar=False)\n",
    "    \n",
    "    if detector.numeroDedos() == 1:\n",
    "        img = cv2.imread('gafas1.jpg')\n",
    "        flag = 1\n",
    "    elif detector.numeroDedos() == 2:\n",
    "        img = cv2.imread('gafas2.jpg')\n",
    "        flag = 1\n",
    "    elif detector.numeroDedos() == 0:\n",
    "        flag = 0\n",
    "\n",
    "    if flag == 1:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, umbral = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        contornos, _ = cv2.findContours(umbral, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        mascara = np.zeros_like(img)\n",
    "        cv2.drawContours(mascara, contornos, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "        objeto_extraido = cv2.bitwise_and(img, mascara)\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "        results2 = face_detection.process(frame_rgb)\n",
    "\n",
    "        if results2.detections:\n",
    "            for detection in results2.detections:\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, _ = frame.shape\n",
    "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "        if results.multi_face_landmarks:\n",
    "            for landmarks in results.multi_face_landmarks:\n",
    "                left_eye = landmarks.landmark[33]\n",
    "                right_eye = landmarks.landmark[133]\n",
    "                left_eye_x = int(left_eye.x * iw)\n",
    "                left_eye_y = int(left_eye.y * ih)\n",
    "                right_eye_x = int(right_eye.x * iw)\n",
    "                right_eye_y = int(right_eye.y * ih)\n",
    "                center_x = (left_eye_x + right_eye_x) // 2 + 35\n",
    "                center_y = (left_eye_y + right_eye_y) // 2\n",
    "                escala_gafas = 1.2\n",
    "                overlay = cv2.resize(objeto_extraido, (int(w * escala_gafas), int(h * escala_gafas)))\n",
    "                new_x = max(center_x - overlay.shape[1] // 2, 0)\n",
    "                new_y = max(center_y - overlay.shape[0] // 2, 0)\n",
    "                n_frame = frame[new_y:new_y+overlay.shape[0], new_x:new_x+overlay.shape[1]]\n",
    "                gray_overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "                _, mask = cv2.threshold(gray_overlay, 1, 255, cv2.THRESH_BINARY)\n",
    "                mask_inv = cv2.bitwise_not(mask)\n",
    "                bg_frame = cv2.bitwise_and(n_frame, n_frame, mask=mask_inv)\n",
    "                fg_overlay = cv2.bitwise_and(overlay, overlay, mask=mask)\n",
    "                result = cv2.add(bg_frame, fg_overlay)\n",
    "                frame[new_y:new_y+overlay.shape[0], new_x:new_x+overlay.shape[1]] = result\n",
    "\n",
    "    # Mostrar el fotograma con las gafas colocadas\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Guardar el fotograma en el video de salida\n",
    "    out.write(frame)\n",
    "    \n",
    "    # Detener la ejecución con la tecla ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "# Liberar la captura de video y cerrar las ventanas\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
